import json
import uuid
from pathlib import Path
from typing import List, Tuple

import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# === ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ ===
load_dotenv()

# === ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š ===
SHORTSTORY_DIR = Path("output/shortstories")
INTEGRATED_DIR = Path("output/integrated/characters")
UPDATED_SHORTSTORY_DIR = Path("output/shortstories_integrated")

# é¡ä¼¼åº¦ã®é–¾å€¤
SIMILARITY_THRESHOLD = 0.90

# === ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ ===
model = SentenceTransformer("intfloat/multilingual-e5-large")


# === Step 1: ShortStoryã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡º ===
def load_all_characters_from_shortstories(
    shortstory_dir: Path,
) -> List[Tuple[dict, str, Path]]:
    entities = []
    for path in shortstory_dir.glob("*.jsonld"):
        with open(path, "r", encoding="utf-8") as f:
            story = json.load(f)
            characters = story.get("character", [])
            for char in characters:
                label = char.get("label", "").strip()
                if label:
                    entities.append((char, label, path))
    return entities


# === Step 2: é¡ä¼¼ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° ===
def deduplicate_entities_by_label_embedding(entities, threshold: float):
    labels = [label for _, label, _ in entities]
    embeddings = model.encode(
        [f"query: {label}" for label in labels], normalize_embeddings=True
    )

    clusters = []
    used = set()

    for i in tqdm(range(len(entities)), desc="ğŸ”— ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®çµ±åˆ"):
        if i in used:
            continue
        cluster = [entities[i]]
        used.add(i)

        for j in range(i + 1, len(entities)):
            if j in used:
                continue
            sim = float(np.dot(embeddings[i], embeddings[j]))
            if sim >= threshold:
                cluster.append(entities[j])
                used.add(j)

        clusters.append(cluster)

    return clusters


# === Step 3: çµ±åˆæ¸ˆã¿ã‚­ãƒ£ãƒ©ã‚’ä¿å­˜ ===
def save_cluster_to_integrated_dir(cluster: List[Tuple[dict, str, Path]], outdir: Path):
    rep = cluster[0][0]
    rep_id = rep.get("@id")
    rep["sameAs"] = [ent[0]["@id"] for ent in cluster[1:]] if len(cluster) > 1 else []
    slug = rep_id.rsplit("/", 1)[-1] if rep_id else f"char_{uuid.uuid4().hex[:8]}"

    outdir.mkdir(parents=True, exist_ok=True)
    outpath = outdir / f"{slug}.jsonld"
    with open(outpath, "w", encoding="utf-8") as f:
        json.dump(rep, f, ensure_ascii=False, indent=2)
    print(f"âœ… ä¿å­˜: {outpath.name}ï¼ˆçµ±åˆæ•°: {len(cluster)}ï¼‰")


# === Step 4: sameAs ãƒãƒƒãƒ—ã‚’æ§‹ç¯‰ï¼ˆold_id â†’ rep_idï¼‰ ===
def build_sameas_map(integrated_dir: Path) -> dict:
    id_map = {}
    for file in integrated_dir.glob("*.jsonld"):
        with open(file, "r", encoding="utf-8") as f:
            rep = json.load(f)
            rep_id = rep.get("@id")
            for old_id in rep.get("sameAs", []):
                id_map[old_id] = rep_id
    return id_map


# === Step 5: ShortStory ã‚’æ›´æ–°ã—ã¦å†ä¿å­˜ ===
def update_shortstory_with_integrated_ids(
    story_path: Path, sameas_map: dict, outdir: Path
):
    with open(story_path, "r", encoding="utf-8") as f:
        story = json.load(f)

    updated = False
    for char in story.get("character", []):
        old_id = char.get("@id")
        if old_id in sameas_map:
            char["@id"] = sameas_map[old_id]
            updated = True

    if updated:
        outdir.mkdir(parents=True, exist_ok=True)
        outpath = outdir / story_path.name
        with open(outpath, "w", encoding="utf-8") as f:
            json.dump(story, f, ensure_ascii=False, indent=2)
        print(f"ğŸ”„ ShortStory æ›´æ–°ä¿å­˜: {outpath.name}")


# === å®Ÿè¡Œæœ¬ä½“ ===
if __name__ == "__main__":
    print("\nğŸ“¦ ShortStory ã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼çµ±åˆå‡¦ç†ã‚’é–‹å§‹")

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŠ½å‡ºã¨çµ±åˆ
    entities = load_all_characters_from_shortstories(SHORTSTORY_DIR)
    clusters = deduplicate_entities_by_label_embedding(entities, SIMILARITY_THRESHOLD)
    for cluster in clusters:
        save_cluster_to_integrated_dir(cluster, INTEGRATED_DIR)

    print("\nğŸ” ShortStory ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼IDã‚’çµ±åˆæ¸ˆã¿ã«å·®ã—æ›¿ãˆä¸­...")
    sameas_map = build_sameas_map(INTEGRATED_DIR)
    for path in SHORTSTORY_DIR.glob("*.jsonld"):
        update_shortstory_with_integrated_ids(path, sameas_map, UPDATED_SHORTSTORY_DIR)

    print("\nğŸ çµ±åˆå‡¦ç†ã¨ ShortStory æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
