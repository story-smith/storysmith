import json
import uuid
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# === ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ ===
load_dotenv()

# === ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š ===
SHORTSTORY_DIR = Path("output/shortstories")
INTEGRATED_BASE_DIR = Path("output/integrated")
UPDATED_SHORTSTORY_DIR = Path("output/shortstories_integrated")

# é¡ä¼¼åº¦ã®é–¾å€¤
SIMILARITY_THRESHOLD = 0.90

# çµ±åˆå¯¾è±¡ã‚¹ãƒ­ãƒƒãƒˆã¨ã‚¹ã‚­ãƒ¼ãƒã‚¿ã‚¤ãƒ—
TARGET_SLOTS = {
    "character": "Person",
    "spatial": "Place",
    "mentions": "Product",
}

# === SBERTãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===
model = SentenceTransformer("intfloat/multilingual-e5-large")


# === Step 1: ShortStoryã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡º ===
def load_entities_from_shortstories(
    slot: str, shortstory_dir: Path
) -> List[Tuple[dict, str, Path]]:
    entities = []
    for path in shortstory_dir.glob("*.jsonld"):
        with open(path, "r", encoding="utf-8") as f:
            story = json.load(f)

        for ent in story.get(slot, []):
            name = ent.get("name", "").strip()
            if name:
                entities.append((ent, name, path))
    return entities


# === Step 2: é¡ä¼¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° ===
def deduplicate_entities(entities: List[Tuple[dict, str, Path]], threshold: float):
    labels = [label for _, label, _ in entities]
    embeddings = model.encode(
        [f"query: {label}" for label in labels], normalize_embeddings=True
    )

    clusters = []
    used = set()
    for i in tqdm(range(len(entities)), desc="ğŸ”— ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£çµ±åˆ"):
        if i in used:
            continue
        cluster = [entities[i]]
        used.add(i)

        for j in range(i + 1, len(entities)):
            if j in used:
                continue
            sim = float(np.dot(embeddings[i], embeddings[j]))
            if sim >= threshold:
                cluster.append(entities[j])
                used.add(j)
        clusters.append(cluster)
    return clusters


# === Step 3: çµ±åˆã‚¯ãƒ©ã‚¹ã‚¿ä¿å­˜ ===
def save_cluster(cluster: List[Tuple[dict, str, Path]], outdir: Path):
    rep = cluster[0][0]
    rep_id = rep.get("@id")
    rep["sameAs"] = [ent[0]["@id"] for ent in cluster[1:]] if len(cluster) > 1 else []
    slug = rep_id.rsplit("/", 1)[-1] if rep_id else f"ent_{uuid.uuid4().hex[:8]}"

    outdir.mkdir(parents=True, exist_ok=True)
    outpath = outdir / f"{slug}.jsonld"
    with open(outpath, "w", encoding="utf-8") as f:
        json.dump(rep, f, ensure_ascii=False, indent=2)
    print(f"âœ… çµ±åˆä¿å­˜: {outpath.name}ï¼ˆ{len(cluster)} ä»¶ï¼‰")


# === Step 4: sameAsãƒãƒƒãƒ—æ§‹ç¯‰ ===
def build_sameas_map(integrated_dir: Path) -> Dict[str, str]:
    id_map = {}
    for path in integrated_dir.glob("*.jsonld"):
        with open(path, "r", encoding="utf-8") as f:
            rep = json.load(f)
        rep_id = rep.get("@id")
        for old_id in rep.get("sameAs", []):
            id_map[old_id] = rep_id
    return id_map


# === Step 5: JSONå†…ã® @id ã‚’ãƒãƒƒãƒ—ã§æ›´æ–° ===
def update_ids_in_slot(story: dict, slot: str, sameas_map: dict) -> bool:
    updated = False
    for ent in story.get(slot, []):
        if ent.get("@id") in sameas_map:
            ent["@id"] = sameas_map[ent["@id"]]
            updated = True
    return updated


# === Step 6: ShortStoryã‚’æ›´æ–°ã—ã¦ä¿å­˜ ===
def update_shortstory_ids(
    story_path: Path, id_maps: Dict[str, Dict[str, str]], outdir: Path
):
    with open(story_path, "r", encoding="utf-8") as f:
        story = json.load(f)

    updated = False
    for slot in TARGET_SLOTS:
        updated |= update_ids_in_slot(story, slot, id_maps[slot])

    if updated:
        outdir.mkdir(parents=True, exist_ok=True)
        outpath = outdir / story_path.name
        with open(outpath, "w", encoding="utf-8") as f:
            json.dump(story, f, ensure_ascii=False, indent=2)
        print(f"ğŸ”„ ShortStoryæ›´æ–°: {outpath.name}")


# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
if __name__ == "__main__":
    print("ğŸš€ çµ±åˆå‡¦ç†é–‹å§‹\n")

    # ã‚¹ãƒ­ãƒƒãƒˆã”ã¨ã«å‡¦ç†
    id_maps = {}
    for slot, type_name in TARGET_SLOTS.items():
        print(f"\nğŸ“‚ {slot} ã®å‡¦ç†ä¸­...")
        ent_dir = INTEGRATED_BASE_DIR / slot
        entities = load_entities_from_shortstories(slot, SHORTSTORY_DIR)
        clusters = deduplicate_entities(entities, SIMILARITY_THRESHOLD)
        for cluster in clusters:
            save_cluster(cluster, ent_dir)
        id_maps[slot] = build_sameas_map(ent_dir)

    # ShortStoryã®æ›´æ–°
    print("\nğŸ›  ShortStory ã® @id ã‚’çµ±åˆæ¸ˆã¿ã«å·®ã—æ›¿ãˆä¸­...")
    for story_path in SHORTSTORY_DIR.glob("*.jsonld"):
        update_shortstory_ids(story_path, id_maps, UPDATED_SHORTSTORY_DIR)

    print("\nâœ… çµ±åˆå‡¦ç†ã¨ ShortStory æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
