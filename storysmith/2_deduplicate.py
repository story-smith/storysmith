import json
from pathlib import Path
from typing import List, Tuple

import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# Load environment variables
load_dotenv()

# === è¨­å®š ===
ENTITY_TYPES = {
    "characters": (
        "output/raw/a-fish-story-story/characters",  # raw_dir: ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒã“ã“ã«ã‚ã‚‹
        "output/integrated/a-fish-story-story/characters",  # out_dir: çµ±åˆçµæœã®ä¿å­˜å…ˆã‚‚åŒã˜æ§‹é€ ã§ä½¿ã†
    ),
    "places": (
        "output/raw/a-fish-story-story/places",
        "output/integrated/a-fish-story-story/places",
    ),
}

SIMILARITY_THRESHOLD = 0.90

# === ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ ===
model = SentenceTransformer("intfloat/multilingual-e5-large")


def load_all_entities(entity_dir: Path) -> List[Tuple[dict, str, str]]:
    """å…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¨ªæ–­ã—ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ä»˜ãï¼‰"""
    entities = []
    for path in entity_dir.glob("section_*/**/*.jsonld"):
        with open(path, "r", encoding="utf-8") as f:
            ent = json.load(f)
            label = ent.get("_features", {}).get("label", "").strip()
            section = ent.get("episode", "").rsplit("_", 1)[-1]
            if label and section:
                entities.append((ent, label, section))
    return entities


def deduplicate_entities_by_label_embedding(entities, threshold: float):
    labels = [label for _, label, _ in entities]
    embeddings = model.encode(
        [f"query: {label}" for label in labels], normalize_embeddings=True
    )

    clusters = []
    used = set()

    for i in tqdm(range(len(entities)), desc="ğŸ”— ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¨ªæ–­ãƒ©ãƒ™ãƒ«çµ±åˆ"):
        if i in used:
            continue
        cluster = [entities[i]]
        used.add(i)

        for j in range(i + 1, len(entities)):
            if j in used:
                continue
            sim = float(np.dot(embeddings[i], embeddings[j]))
            if sim >= threshold:
                cluster.append(entities[j])
                used.add(j)

        clusters.append(cluster)

    return clusters


def save_cluster_to_sections(cluster: List[Tuple[dict, str, str]], output_base: Path):
    rep = cluster[0][0]
    rep_id = rep["@id"]
    rep["sameAs"] = [ent[0]["@id"] for ent in cluster[1:]] if len(cluster) > 1 else []
    slug = rep_id.rsplit("/", 1)[-1]

    sections = {section for _, _, section in cluster}
    for section in sections:
        output_dir = output_base / f"section_{section}"
        output_dir.mkdir(parents=True, exist_ok=True)
        outpath = output_dir / f"{slug}.jsonld"
        with open(outpath, "w", encoding="utf-8") as f:
            json.dump(rep, f, ensure_ascii=False, indent=2)
        print(f"âœ… ä¿å­˜: {outpath.name}ï¼ˆsection {section}, åŒä¸€:{len(cluster)}ï¼‰")


# === å®Ÿè¡Œ ===
if __name__ == "__main__":
    for type_name, (raw_dir, out_dir) in ENTITY_TYPES.items():
        print(f"\nğŸ“¦ çµ±åˆä¸­: {type_name}")
        entities = load_all_entities(Path(raw_dir))
        clusters = deduplicate_entities_by_label_embedding(
            entities, SIMILARITY_THRESHOLD
        )
        for cluster in clusters:
            save_cluster_to_sections(cluster, Path(out_dir))

    print("\nğŸ çµ±åˆï¼‹å‡ºç¾ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã®ä¿å­˜å®Œäº†ï¼")
